{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import Union, List, Callable, Optional, Tuple, Literal\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "Scalar = Union[int, float]\n",
    "\n",
    "Data = Union[Scalar, list, np.ndarray, \"Tensor\"]\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class Leaf:\n",
    "    value: \"Tensor\"\n",
    "    grad_fn: Callable[[np.ndarray], np.ndarray]\n",
    "\n",
    "\n",
    "class Tensor:\n",
    "    def __init__(\n",
    "        self,\n",
    "        data: Data,\n",
    "        requires_grad: bool = False,\n",
    "        dependencies: Optional[List[Leaf]] = None,\n",
    "        dtype=np.float32\n",
    "    ):\n",
    "        self._data = Tensor.build_ndarray(data, dtype)\n",
    "        self.dtype = dtype\n",
    "\n",
    "        self.requires_grad = requires_grad\n",
    "        self.dependencies = dependencies or []\n",
    "\n",
    "        self.grad = np.zeros_like(self._data) if requires_grad else None\n",
    "\n",
    "    @property\n",
    "    def data(self) -> np.ndarray:\n",
    "        return self._data\n",
    "\n",
    "    @data.setter\n",
    "    def data(self, data: Data):\n",
    "        self._data = Tensor.build_ndarray(data, self.dtype)\n",
    "        if self.requires_grad:\n",
    "            self.zero_grad()\n",
    "\n",
    "    @property\n",
    "    def size(self) -> int:\n",
    "        return self.data.size\n",
    "\n",
    "    @property\n",
    "    def shape(self) -> Tuple[int, ...]:\n",
    "        return self.data.shape\n",
    "\n",
    "    @property\n",
    "    def ndim(self) -> int:\n",
    "        return self.data.ndim\n",
    "\n",
    "    @staticmethod\n",
    "    def build_ndarray(data: Data, dtype=np.float32) -> np.ndarray:\n",
    "        if isinstance(data, Tensor):\n",
    "            return np.array(data.data, dtype=dtype)\n",
    "        if isinstance(data, np.ndarray):\n",
    "            return data.astype(dtype)\n",
    "        return np.array(data, dtype=dtype)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"Tensor({self.data}, requires_grad={self.requires_grad}, shape={self.shape})\"\n",
    "    \n",
    "    def zero_grad(self):\n",
    "        if self.grad is None:\n",
    "            self.grad = np.zeros_like(self._data)\n",
    "        else:\n",
    "            self.grad.fill(0.0)\n",
    "\n",
    "    def backward(self, grad: Optional[np.ndarray] = None) -> None:\n",
    "        if not self.requires_grad:\n",
    "            raise RuntimeError(\n",
    "                \"Cannot call backward() on a tensor that does not require gradients. \"\n",
    "                \"If you need gradients, ensure that requires_grad=True when creating the tensor.\"\n",
    "            )\n",
    "\n",
    "        if grad is None:\n",
    "            if grad.shape == ():\n",
    "                grad = np.array(1.0)\n",
    "            else:\n",
    "                raise ValueError(\"Grad must be provided if tensor has shape\")\n",
    "            \n",
    "        self.grad = self.grad + grad\n",
    "\n",
    "        for dependency in self.dependencies:\n",
    "            backward_grad = dependency.grad_fn(grad)\n",
    "            dependency.value.backward(backward_grad)\n",
    "\n",
    "    def transpose(self, axes: Tuple[int, ...] = None) -> \"Tensor\":\n",
    "        output = np.transpose(self.data, axes=axes)\n",
    "        dependencies: List[Leaf] = []\n",
    "\n",
    "        def _bkwd(grad: np.ndarray) -> np.ndarray:\n",
    "            return np.transpose(grad, axes=axes)\n",
    "        \n",
    "        if self.requires_grad:\n",
    "            dependencies.append(\n",
    "                Leaf(value=self, grad_fn=_bkwd)\n",
    "            )\n",
    "\n",
    "        return Tensor(\n",
    "            output,\n",
    "            requires_grad=self.requires_grad,\n",
    "            dependencies=dependencies\n",
    "        )\n",
    "\n",
    "    @property\n",
    "    def T(self):\n",
    "        return self.transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chain Rule\n",
    "\n",
    "$$\n",
    "\\frac{dz}{dx} = \\frac{dz}{dy} \\cdot \\frac{dy}{dx}\n",
    "$$\n",
    "\n",
    "If we have a function composition:  \n",
    "\n",
    "$$\n",
    "f(x) = g(h(x))\n",
    "$$\n",
    "\n",
    "Then, by the chain rule:\n",
    "\n",
    "$$\n",
    "f'(x) = g'(h(x)) \\cdot h'(x)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = Tensor([1, 2, 3], requires_grad=True)\n",
    "t.data = [[1, 3, 5], [2, 3, 4]]\n",
    "t_T = t.T\n",
    "\n",
    "t_T.backward(np.ones_like(t_T.data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "InitMethod = Literal[\"xavier\", \"he\", \"he_leaky\", \"normal\", \"uniform\"]\n",
    "\n",
    "\n",
    "class Parameter(Tensor):\n",
    "    def __init__(\n",
    "        self,\n",
    "        *shape: int,\n",
    "        data: Optional[np.ndarray] = None,\n",
    "        init_method: InitMethod = \"xavier\",\n",
    "        gain: float = 1.0,\n",
    "    ):\n",
    "        if data in None:\n",
    "            data = self._init(shape, init_method, gain)\n",
    "\n",
    "        super().__init__(data=data, requires_grad=True)\n",
    "\n",
    "    def _init(self, shape: Tuple[int, ...], init_method: InitMethod = \"xavier\", gain: float = 1.0, alpha: float = 0.01):\n",
    "        weights = np.random.randn(*shape)\n",
    "\n",
    "        if init_method == \"xavier\":\n",
    "            std = gain * np.sqrt(1.0 / shape[0])\n",
    "            return std * weights\n",
    "        if init_method == \"he\":\n",
    "            std = gain * np.sqrt(2.0 / shape[0])\n",
    "            return std * weights\n",
    "        if init_method == \"he_leaky\":\n",
    "            std = gain * np.sqrt(2.0 / (1 + alpha**2) * (1 / shape[0]))\n",
    "            return std * weights\n",
    "        if init_method == \"normal\":\n",
    "            return gain * weights\n",
    "        if init_method == \"uniform\":\n",
    "            return gain * np.random.uniform(-1, 1, size=shape)\n",
    "\n",
    "        raise ValueError(f\"Unknown initialization method: {init_method}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Iterator\n",
    "\n",
    "class Module:\n",
    "    def __call__(self, *args, **kwds) -> Tensor:\n",
    "        self.forward(*args, **kwds)\n",
    "\n",
    "    def forward(self, *input):\n",
    "        raise NotImplementedError()\n",
    "    \n",
    "    def parameters(self) -> Iterator[Parameter]:\n",
    "        for _, item in self.__dict__.items():\n",
    "            if isinstance(item, Parameter):\n",
    "                yield item\n",
    "            if isinstance(item, Module):\n",
    "                yield from item.parameters()\n",
    "    \n",
    "    def zero_grad(self) -> None:\n",
    "        for param in self.parameters():\n",
    "            param.zero_grad()\n",
    "\n",
    "\n",
    "class Sequential(Module):\n",
    "    def __init__(self, *modules: Module):\n",
    "        super.__init__()\n",
    "        self.modules = modules\n",
    "\n",
    "    def parameters(self) -> Iterator[Parameter]:\n",
    "        for module in self.modules:\n",
    "            yield from module.parameters()\n",
    "\n",
    "    def forward(self, *input):\n",
    "        for module in self.modules:\n",
    "            input = module(*input)\n",
    "        return input"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "au2grad",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
