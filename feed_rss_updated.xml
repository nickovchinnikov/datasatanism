<?xml version="1.0" encoding="UTF-8" ?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:dc="http://purl.org/dc/elements/1.1/"> <channel><title>DataSanta</title><link>https://datasanta.net/</link><atom:link href="https://datasanta.net/feed_rss_updated.xml" rel="self" type="application/rss+xml" /><language>en</language> <pubDate>Wed, 16 Apr 2025 18:51:20 -0000</pubDate> <lastBuildDate>Wed, 16 Apr 2025 18:51:20 -0000</lastBuildDate> <ttl>1440</ttl> <generator>MkDocs RSS plugin - v1.17.1</generator> <image> <url>None</url> <title>DataSanta</title><link>https://datasanta.net/</link> </image> <item> <title>Empirical Risk and Cross-Entropy in MicroTorch</title> <author>Nick Ovchinnikov</author> <description>Dive deep into loss functions, expected risk in the MicroTorch.</description><link>https://datasanta.net/2025/04/13/empirical-risk-and-cross-entropy-in-microtorch/</link> <pubDate>Wed, 16 Apr 2025 18:50:51 +0000</pubDate><source url="https://datasanta.net/feed_rss_updated.xml">DataSanta</source><guid isPermaLink="true">https://datasanta.net/2025/04/13/empirical-risk-and-cross-entropy-in-microtorch/</guid> <enclosure url="https://datasanta.net/assets/images/social/2025/04/13/empirical-risk-and-cross-entropy-in-microtorch.png" type="image/png" length="None" /> </item> <item> <title>MicroTorch - Deep Learning from Scratch!</title> <author>Nick Ovchinnikov</author> <description>Learn how to build a PyTorch-like, autograd-powered Deep Learning Framework with automatic differentiation.</description><link>https://datasanta.net/2025/04/03/microtorch---deep-learning-from-scratch/</link> <pubDate>Wed, 16 Apr 2025 18:50:51 +0000</pubDate><source url="https://datasanta.net/feed_rss_updated.xml">DataSanta</source><guid isPermaLink="true">https://datasanta.net/2025/04/03/microtorch---deep-learning-from-scratch/</guid> <enclosure url="https://datasanta.net/assets/images/social/2025/04/03/microtorch---deep-learning-from-scratch.png" type="image/png" length="None" /> </item> <item> <title>Classification - Cross-Entropy &amp; Softmax</title> <author>Nick Ovchinnikov</author> <description>Implement the Cross-Entropy &amp; Softmax. Tackle the Fashion-MNIST challenge!</description><link>https://datasanta.net/2025/02/05/classification---cross-entropy--softmax/</link> <pubDate>Wed, 16 Apr 2025 18:50:51 +0000</pubDate><source url="https://datasanta.net/feed_rss_updated.xml">DataSanta</source><guid isPermaLink="true">https://datasanta.net/2025/02/05/classification---cross-entropy--softmax/</guid> <enclosure url="https://datasanta.net/assets/images/social/2025/02/05/classification---cross-entropy--softmax.png" type="image/png" length="None" /> </item> <item> <title>Cross Entropy Loss</title> <author>Nick Ovchinnikov</author> <description>A concise guide to Cross-Entropy loss with step-by-step explanations and visualizations.</description><link>https://datasanta.net/2024/12/28/cross-entropy-loss/</link> <pubDate>Wed, 16 Apr 2025 18:50:51 +0000</pubDate><source url="https://datasanta.net/feed_rss_updated.xml">DataSanta</source><guid isPermaLink="true">https://datasanta.net/2024/12/28/cross-entropy-loss/</guid> <enclosure url="https://datasanta.net/assets/images/social/2024/12/28/cross-entropy-loss.png" type="image/png" length="None" /> </item> <item> <title>Solving Non-Linear Patterns with Deep Neural Network</title> <author>Nick Ovchinnikov</author> <description>Multi-Layer neural networks solve complex, non-linear problems like the spiral dataset</description><link>https://datasanta.net/2025/01/28/solving-non-linear-patterns-with-deep-neural-network/</link> <pubDate>Wed, 16 Apr 2025 18:50:51 +0000</pubDate><source url="https://datasanta.net/feed_rss_updated.xml">DataSanta</source><guid isPermaLink="true">https://datasanta.net/2025/01/28/solving-non-linear-patterns-with-deep-neural-network/</guid> <enclosure url="https://datasanta.net/assets/images/social/2025/01/28/solving-non-linear-patterns-with-deep-neural-network.png" type="image/png" length="None" /> </item> <item> <title>Dive into Learning from Data - MNIST Video Adventure</title> <author>Nick Ovchinnikov</author> <description>We&#39;re diving into the realm of MNIST, a dataset that&#39;s like a treasure map for budding data scientists.</description><link>https://datasanta.net/2024/11/26/dive-into-learning-from-data---mnist-video-adventure/</link> <pubDate>Wed, 16 Apr 2025 18:50:51 +0000</pubDate><source url="https://datasanta.net/feed_rss_updated.xml">DataSanta</source><guid isPermaLink="true">https://datasanta.net/2024/11/26/dive-into-learning-from-data---mnist-video-adventure/</guid> <enclosure url="https://datasanta.net/assets/images/social/2024/11/26/dive-into-learning-from-data---mnist-video-adventure.png" type="image/png" length="None" /> </item> <item> <title>Gradient Descent - Downhill to the Minima</title> <author>Nick Ovchinnikov</author> <description>Follow along with our interactive Python plot where we demonstrate the gradient descent in action.</description><link>https://datasanta.net/2024/12/05/gradient-descent---downhill-to-the-minima/</link> <pubDate>Wed, 16 Apr 2025 18:50:51 +0000</pubDate><source url="https://datasanta.net/feed_rss_updated.xml">DataSanta</source><guid isPermaLink="true">https://datasanta.net/2024/12/05/gradient-descent---downhill-to-the-minima/</guid> <enclosure url="https://datasanta.net/assets/images/social/2024/12/05/gradient-descent---downhill-to-the-minima.png" type="image/png" length="None" /> </item> <item> <title>Gradient Descent Ninja with Momentum</title> <author>Nick Ovchinnikov</author> <description>Explore the gradient descent through a practical journey from simple paraboloids to complex functions.</description><link>https://datasanta.net/2024/12/12/gradient-descent-ninja-with-momentum/</link> <pubDate>Wed, 16 Apr 2025 18:50:51 +0000</pubDate><source url="https://datasanta.net/feed_rss_updated.xml">DataSanta</source><guid isPermaLink="true">https://datasanta.net/2024/12/12/gradient-descent-ninja-with-momentum/</guid> <enclosure url="https://datasanta.net/assets/images/social/2024/12/12/gradient-descent-ninja-with-momentum.png" type="image/png" length="None" /> </item> <item> <title>Mastering Neural Network - Linear Layer and SGD</title> <author>Nick Ovchinnikov</author> <description>Neural Network Training with Stochastic Gradient Descent (SGD)</description><link>https://datasanta.net/2025/01/22/mastering-neural-network---linear-layer-and-sgd/</link> <pubDate>Wed, 16 Apr 2025 18:50:51 +0000</pubDate><source url="https://datasanta.net/feed_rss_updated.xml">DataSanta</source><guid isPermaLink="true">https://datasanta.net/2025/01/22/mastering-neural-network---linear-layer-and-sgd/</guid> <enclosure url="https://datasanta.net/assets/images/social/2025/01/22/mastering-neural-network---linear-layer-and-sgd.png" type="image/png" length="None" /> </item> <item> <title>The journey from Logits to Probabilities</title> <author>Nick Ovchinnikov</author> <description>How the sigmoid function transforms raw model outputs (logits) into probabilities</description><link>https://datasanta.net/2025/01/03/the-journey-from-logits-to-probabilities/</link> <pubDate>Wed, 16 Apr 2025 18:50:51 +0000</pubDate><source url="https://datasanta.net/feed_rss_updated.xml">DataSanta</source><guid isPermaLink="true">https://datasanta.net/2025/01/03/the-journey-from-logits-to-probabilities/</guid> <enclosure url="https://datasanta.net/assets/images/social/2025/01/03/the-journey-from-logits-to-probabilities.png" type="image/png" length="None" /> </item> <item> <title>Matrix Multiplication and Broadcasting</title> <author>Nick Ovchinnikov</author> <description>The Heartbeat of Data Transformations - Dive into the essentials of matrix multiplication and broadcasting.</description><link>https://datasanta.net/2024/11/20/matrix-multiplication-and-broadcasting/</link> <pubDate>Wed, 16 Apr 2025 18:50:51 +0000</pubDate><source url="https://datasanta.net/feed_rss_updated.xml">DataSanta</source><guid isPermaLink="true">https://datasanta.net/2024/11/20/matrix-multiplication-and-broadcasting/</guid> <enclosure url="https://datasanta.net/assets/images/social/2024/11/20/matrix-multiplication-and-broadcasting.png" type="image/png" length="None" /> </item> <item> <title>Mastering Derivatives From Math to Code</title> <author>Nick Ovchinnikov</author> <description>Dive into the world of derivatives, from understanding the mathematical fundamentals to implementing Python code.</description><link>https://datasanta.net/2024/11/30/mastering-derivatives-from-math-to-code/</link> <pubDate>Wed, 16 Apr 2025 18:50:51 +0000</pubDate><source url="https://datasanta.net/feed_rss_updated.xml">DataSanta</source><guid isPermaLink="true">https://datasanta.net/2024/11/30/mastering-derivatives-from-math-to-code/</guid> <enclosure url="https://datasanta.net/assets/images/social/2024/11/30/mastering-derivatives-from-math-to-code.png" type="image/png" length="None" /> </item> <item> <title>Instability in Numerical Differentiation</title> <author>Nick Ovchinnikov</author> <description>Delving into the pitfalls of numerical differentiation, exploring its impact on gradient computation.</description><link>https://datasanta.net/2024/12/10/instability-in-numerical-differentiation/</link> <pubDate>Wed, 16 Apr 2025 18:50:51 +0000</pubDate><source url="https://datasanta.net/feed_rss_updated.xml">DataSanta</source><guid isPermaLink="true">https://datasanta.net/2024/12/10/instability-in-numerical-differentiation/</guid> <enclosure url="https://datasanta.net/assets/images/social/2024/12/10/instability-in-numerical-differentiation.png" type="image/png" length="None" /> </item> <item> <title>Text-to-Speech (TTS) Models Overview, Little Theory and Math</title> <author>Nick Ovchinnikov</author> <description>Training Text-to-Speech Models - A Journey from Zero to...</description><link>https://datasanta.net/2024/06/11/text-to-speech-tts-models-overview-little-theory-and-math/</link> <pubDate>Wed, 16 Apr 2025 18:50:51 +0000</pubDate><source url="https://datasanta.net/feed_rss_updated.xml">DataSanta</source><guid isPermaLink="true">https://datasanta.net/2024/06/11/text-to-speech-tts-models-overview-little-theory-and-math/</guid> <enclosure url="https://datasanta.net/assets/images/social/2024/06/11/text-to-speech-tts-models-overview-little-theory-and-math.png" type="image/png" length="None" /> </item> <item> <title>Weight Initialization Methods in Neural Networks</title> <author>Nick Ovchinnikov</author> <description>From Gaussian to Xavier and He methods, with math foundations and code examples.</description><link>https://datasanta.net/2025/01/14/weight-initialization-methods-in-neural-networks/</link> <pubDate>Wed, 16 Apr 2025 18:50:51 +0000</pubDate><source url="https://datasanta.net/feed_rss_updated.xml">DataSanta</source><guid isPermaLink="true">https://datasanta.net/2025/01/14/weight-initialization-methods-in-neural-networks/</guid> <enclosure url="https://datasanta.net/assets/images/social/2025/01/14/weight-initialization-methods-in-neural-networks.png" type="image/png" length="None" /> </item> <item> <title>SGD, Momentum &amp; Exploding Gradient</title> <author>Nick Ovchinnikov</author> <description>Why does gradient descent struggle with exploding gradients? Make SGD stable!</description><link>https://datasanta.net/2025/02/01/sgd-momentum--exploding-gradient/</link> <pubDate>Wed, 05 Feb 2025 00:00:00 +0000</pubDate><source url="https://datasanta.net/feed_rss_updated.xml">DataSanta</source><guid isPermaLink="true">https://datasanta.net/2025/02/01/sgd-momentum--exploding-gradient/</guid> <enclosure url="https://datasanta.net/assets/images/social/2025/02/01/sgd-momentum--exploding-gradient.png" type="image/png" length="None" /> </item> <item> <title>Why Does the Gradient Point Upwards?</title> <author>Nick Ovchinnikov</author> <description>Explore why the gradient vector indicates the direction of steepest ascent for functions.</description><link>https://datasanta.net/2024/12/04/why-does-the-gradient-point-upwards/</link> <pubDate>Sat, 07 Dec 2024 00:00:00 +0000</pubDate><source url="https://datasanta.net/feed_rss_updated.xml">DataSanta</source><guid isPermaLink="true">https://datasanta.net/2024/12/04/why-does-the-gradient-point-upwards/</guid> <enclosure url="https://datasanta.net/assets/images/social/2024/12/04/why-does-the-gradient-point-upwards.png" type="image/png" length="None" /> </item> </channel></rss>